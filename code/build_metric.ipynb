{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Metric\n",
    "\n",
    "In this notebook, tackle opportunity, missed tackle opportunity, and tackle conversions are tabulated for every defensive player with solo tackles > 30. Subsequently, the tackle opportunity rate, missed tackle opportunity rate, and tackle conversion rate are derived using the total active plays that each player is involved in. The data is then visualized in a variety of manners to highlight patterns and assess individual player performance. \n",
    "\n",
    "Steps: \n",
    "1) Load model trained from train_model.ipynb\n",
    "2) Load tracking data preprocessed from load_data.ipynb\n",
    "3) Run inference on every play in the tracking data, and tabulate tackle opportunities, missed tackle opportunities, and tackle conversions \n",
    "4) Convert these metrics into rates\n",
    "5) Visualize data in a variety of tables and plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle \n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from datetime import datetime\n",
    "\n",
    "from data_preprocessing import build_inference_tackle_sequences\n",
    "\n",
    "root_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model...\n",
      "Loading Tracking Data...\n"
     ]
    }
   ],
   "source": [
    "# Load model into XGBoost Model \n",
    "print(\"Loading Model...\")\n",
    "clf = xgb.XGBClassifier()\n",
    "clf.load_model(os.path.join(root_dir, \"save/XGBoost_01082024-1705.model\"))\n",
    "\n",
    "# Load tracking data \n",
    "print(\"Loading Tracking Data...\")\n",
    "df_tracking_test = pickle.load(open(os.path.join(root_dir, \"save/test_tracking_data_01072024-2324.pkl\"), \"rb\"))\n",
    "df_tracking_train = pickle.load(open(os.path.join(root_dir, \"save/train_tracking_data_01072024-2324.pkl\"), \"rb\"))\n",
    "ts_lists = pickle.load(open(os.path.join(root_dir, \"save/tackle_sequences_01072024-2324.pkl\"), \"rb\"))\n",
    "tackle_sequences_train = ts_lists[\"train\"]\n",
    "tackle_sequences_test = ts_lists[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabulate Metrics\n",
    "\n",
    "Calculate tackle opportunities, missed opportunities, and conversion rate.\n",
    "Tackle opportunity as any instance where the tackle probability increases above 75% > 0.5 seconds consecutively\n",
    "Missed tackle opportunity as any instance where the tackle probability increases above 75% > 0.5 seconds consecutively, and subsequently decreases below 75% for > 0.5 seconds consecutively\n",
    "\n",
    "**NOTE: Tabulating metrics on all plays takes a little over 3 hours on an M1 Macbook Pro**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c7/4djdm2814z51mg9ff4pvhx_r0000gn/T/ipykernel_46112/332169060.py:87: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_converted_tackles = pd.concat([df_converted_tackles, df_player_stats])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed analysis for player 35466, skipped_ct = 0, active_plays_ct = 361, tackle_made_ct = 45, tackle_opp_ct = 67, missed_opp_ct = 9, tackle_conversion_rate = 0.67\n",
      "Completed analysis for player 38559, skipped_ct = 0, active_plays_ct = 296, tackle_made_ct = 41, tackle_opp_ct = 67, missed_opp_ct = 8, tackle_conversion_rate = 0.61\n",
      "Completed analysis for player 38577, skipped_ct = 0, active_plays_ct = 336, tackle_made_ct = 60, tackle_opp_ct = 126, missed_opp_ct = 30, tackle_conversion_rate = 0.48\n",
      "Completed analysis for player 38588, skipped_ct = 0, active_plays_ct = 391, tackle_made_ct = 55, tackle_opp_ct = 120, missed_opp_ct = 36, tackle_conversion_rate = 0.46\n",
      "Completed analysis for player 41243, skipped_ct = 0, active_plays_ct = 393, tackle_made_ct = 82, tackle_opp_ct = 167, missed_opp_ct = 47, tackle_conversion_rate = 0.49\n",
      "Completed analysis for player 41300, skipped_ct = 0, active_plays_ct = 337, tackle_made_ct = 51, tackle_opp_ct = 117, missed_opp_ct = 26, tackle_conversion_rate = 0.44\n",
      "Completed analysis for player 42368, skipped_ct = 0, active_plays_ct = 395, tackle_made_ct = 65, tackle_opp_ct = 135, missed_opp_ct = 47, tackle_conversion_rate = 0.48\n",
      "Completed analysis for player 42388, skipped_ct = 0, active_plays_ct = 354, tackle_made_ct = 60, tackle_opp_ct = 125, missed_opp_ct = 22, tackle_conversion_rate = 0.48\n",
      "Completed analysis for player 42427, skipped_ct = 0, active_plays_ct = 318, tackle_made_ct = 68, tackle_opp_ct = 122, missed_opp_ct = 25, tackle_conversion_rate = 0.56\n",
      "Completed analysis for player 42929, skipped_ct = 0, active_plays_ct = 206, tackle_made_ct = 56, tackle_opp_ct = 98, missed_opp_ct = 21, tackle_conversion_rate = 0.57\n",
      "Completed analysis for player 43325, skipped_ct = 0, active_plays_ct = 327, tackle_made_ct = 66, tackle_opp_ct = 130, missed_opp_ct = 29, tackle_conversion_rate = 0.51\n",
      "Completed analysis for player 43350, skipped_ct = 0, active_plays_ct = 373, tackle_made_ct = 36, tackle_opp_ct = 103, missed_opp_ct = 17, tackle_conversion_rate = 0.35\n",
      "Completed analysis for player 43353, skipped_ct = 0, active_plays_ct = 337, tackle_made_ct = 52, tackle_opp_ct = 77, missed_opp_ct = 7, tackle_conversion_rate = 0.68\n",
      "Completed analysis for player 43404, skipped_ct = 0, active_plays_ct = 310, tackle_made_ct = 60, tackle_opp_ct = 124, missed_opp_ct = 30, tackle_conversion_rate = 0.48\n",
      "Completed analysis for player 44830, skipped_ct = 0, active_plays_ct = 299, tackle_made_ct = 38, tackle_opp_ct = 63, missed_opp_ct = 16, tackle_conversion_rate = 0.60\n",
      "Completed analysis for player 44848, skipped_ct = 0, active_plays_ct = 404, tackle_made_ct = 66, tackle_opp_ct = 134, missed_opp_ct = 26, tackle_conversion_rate = 0.49\n",
      "Completed analysis for player 44888, skipped_ct = 0, active_plays_ct = 348, tackle_made_ct = 58, tackle_opp_ct = 120, missed_opp_ct = 28, tackle_conversion_rate = 0.48\n",
      "Completed analysis for player 44911, skipped_ct = 0, active_plays_ct = 279, tackle_made_ct = 36, tackle_opp_ct = 55, missed_opp_ct = 17, tackle_conversion_rate = 0.65\n",
      "Completed analysis for player 44925, skipped_ct = 0, active_plays_ct = 391, tackle_made_ct = 63, tackle_opp_ct = 112, missed_opp_ct = 25, tackle_conversion_rate = 0.56\n",
      "Completed analysis for player 44926, skipped_ct = 0, active_plays_ct = 396, tackle_made_ct = 49, tackle_opp_ct = 103, missed_opp_ct = 32, tackle_conversion_rate = 0.48\n",
      "Completed analysis for player 44957, skipped_ct = 0, active_plays_ct = 284, tackle_made_ct = 45, tackle_opp_ct = 101, missed_opp_ct = 39, tackle_conversion_rate = 0.45\n",
      "Completed analysis for player 44976, skipped_ct = 0, active_plays_ct = 267, tackle_made_ct = 36, tackle_opp_ct = 85, missed_opp_ct = 27, tackle_conversion_rate = 0.42\n",
      "Completed analysis for player 44999, skipped_ct = 0, active_plays_ct = 382, tackle_made_ct = 52, tackle_opp_ct = 94, missed_opp_ct = 16, tackle_conversion_rate = 0.55\n"
     ]
    }
   ],
   "source": [
    "# Step 1) Identify defensive players with > X tackles\n",
    "ts_list_total = tackle_sequences_test + tackle_sequences_train\n",
    "df_players = pd.read_csv(os.path.join(root_dir, \"data/players.csv\"))\n",
    "df_tackles = pd.read_csv(os.path.join(root_dir, \"data/tackles.csv\"))\n",
    "df_tracking = pd.concat([df_tracking_train, df_tracking_test])\n",
    "tks_by_player = df_tackles.groupby(\"nflId\").sum()\n",
    "tks_by_player = tks_by_player.drop(columns=[\"gameId\", \"playId\"])            # these cols no longer have meaning after sum()\n",
    "made_tks_30 = tks_by_player[tks_by_player[\"tackle\"] > 30]\n",
    "ids = made_tks_30.index.tolist()\n",
    "\n",
    "# Step 2) For each of those defensive players, iterate through all plays and identify the ones that they are involved in\n",
    "df_converted_tackles = pd.DataFrame(columns=[\"nflId\", \"display_name\", \"active_plays\", \"position\", \"made_tackles\", \"tackle_opportunities\", \"tackle_opportunity_rate\", \"missed_opportunity_rate\", \"tackle_conversion_ratio\"])\n",
    "for id in ids: \n",
    "    skipped_ct = 0          # counter for skipped plays\n",
    "    tackle_opp_ct = 0       # tackle opportunity counter\n",
    "    missed_opp_ct = 0       # missed tackle opportunity counter\n",
    "    tackle_made_ct = 0      # made tackle counter\n",
    "    \n",
    "    df_with_player = df_tracking[(df_tracking.nflId == id)]\n",
    "    gb = df_with_player.groupby([\"gameId\", \"playId\"])\n",
    "    \n",
    "    # Below, iterate through each (gameId, playId) combo that the defender is involved in. Extract the tracking data for both the defender and the ballcarrier of the play. Run inference. \n",
    "    for (gameId, playId), _ in gb: \n",
    "        df_tracking_play = df_tracking[(df_tracking.gameId == gameId) & (df_tracking.playId == playId) & ((df_tracking.nflId == id) | (df_tracking.nflId == df_tracking.ballCarrierId))]\n",
    "        ts_list = build_inference_tackle_sequences(df_tracking_play, gameId, playId, id, offset_frames=10, sequence_len=1, dt=1, verbose=False)\n",
    "        if len(ts_list) == 0: \n",
    "            skipped_ct += 1\n",
    "            continue\n",
    "        \n",
    "        # Step 3) Run inference, and track state to assign tackle opportunities and missed opportunities \n",
    "        state = 0       # state tracker to count tackle opps and missed tackles \n",
    "                        # state = 0, no opportunity\n",
    "                        # state = 11-14, tackle opp counter for 1-4 frames. Tackle opp assigned if prob is > 75% when state == 14\n",
    "                        # state = 15, tackle opp steady state\n",
    "                        # state = 21 - 24, missed tackle opp counter for 1-4 frames. Missed tackle opp assigned if prob is < 75% when state == 24\n",
    "\n",
    "        for ts in ts_list:\n",
    "            x = ts.input_tensor\n",
    "            x = x.view(x.shape[0], -1).cpu().numpy()\n",
    "            probs = clf.predict_proba(x)\n",
    "            \n",
    "            if probs[0, 1] > 0.75:\n",
    "                if state == 0: \n",
    "                    state = 11\n",
    "                elif state in [11, 12, 13]:  # increment tackle opp counter\n",
    "                    state += 1\n",
    "                elif state == 14:                # assign tackle opp\n",
    "                    state += 1                   # enter tackle opp steady state\n",
    "                    tackle_opp_ct += 1         \n",
    "                elif state in [21, 22, 23, 24]:  # return back to tackle opp steady state, disable missed tackle opp counter\n",
    "                    state = 15\n",
    "            else:\n",
    "                if state in [0, 11, 12, 13, 14]:  # reset tackle opp counter\n",
    "                    state = 0\n",
    "                elif state == 15:                 # start missed tackle opp counter\n",
    "                    state = 21\n",
    "                elif state in [21, 22, 23]:       # increment missed tackle opp counter\n",
    "                    state += 1\n",
    "                elif state == 24:                 # assign missed tackle opp, return to state 0\n",
    "                    state = 0\n",
    "                    missed_opp_ct += 1\n",
    "                \n",
    "        # Step 4) Cross-reference tackles.csv to see if the player successfully made a tackle or not \n",
    "        tks_myPlayer = df_tackles[(df_tackles.gameId == gameId) & (df_tackles.playId == playId) & (df_tackles.nflId == id)]\n",
    "        if tks_myPlayer.empty:\n",
    "            pass\n",
    "        elif ((tks_myPlayer.tackle == 1) | (tks_myPlayer.assist == 1)).item():\n",
    "            tackle_made_ct += 1\n",
    "\n",
    "    # Step 5) Tabulate all statistics and rates\n",
    "    player_stats = {\"nflId\": [id], \n",
    "                    \"display_name\": [df_players[df_players.nflId == id].displayName.values[0]],\n",
    "                    \"active_plays\": [len(gb)],\n",
    "                    \"position\": [df_players[df_players.nflId == id].position.values[0]],\n",
    "                    \"made_tackles\": [tackle_made_ct],\n",
    "                    \"tackle_opportunities\": [tackle_opp_ct],\n",
    "                    \"missed_opportunities\": [missed_opp_ct],\n",
    "                    \"tackle_opportunity_rate\": [tackle_opp_ct / len(gb)],\n",
    "                    \"missed_opportunity_rate\": [missed_opp_ct / tackle_opp_ct],\n",
    "                    \"tackle_conversion_rate\": [tackle_made_ct / tackle_opp_ct]\n",
    "                    }\n",
    "    df_player_stats = pd.DataFrame(player_stats, index=player_stats[\"nflId\"])\n",
    "    df_converted_tackles = pd.concat([df_converted_tackles, df_player_stats])\n",
    "    print(f\"Completed analysis for player {id}, skipped_ct = {skipped_ct}, active_plays_ct = {len(gb)}, tackle_made_ct = {tackle_made_ct}, tackle_opp_ct = {tackle_opp_ct}, missed_opp_ct = {missed_opp_ct}, tackle_conversion_rate = {(tackle_made_ct / tackle_opp_ct):.2f}\")\n",
    "    \n",
    "# Save computed tackle opportunity data\n",
    "current_datetime = datetime.now().strftime(\"%m%d%Y-%H%M\")\n",
    "pickle.dump(df_converted_tackles, open(os.path.join(root_dir, f\"tacklenet/inputs/tackle_opportunity_data_{current_datetime}.pkl\"), \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output tackle opp, missed tackle opp, and rate data in HTML table format for the secondary \n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Make HTML Tables\n",
    "def value_to_cell_color(value, ranges):\n",
    "    norm_value = (value - ranges[0]) / (ranges[1] - ranges[0])\n",
    "    \n",
    "    # Create a ScalarMappable to map the normalized value to a color in \"coolwarm\"\n",
    "    cmap = plt.get_cmap('summer_r')\n",
    "    norm = mcolors.Normalize(vmin=0, vmax=1)\n",
    "    scalar_mappable = cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "\n",
    "    # Get the RGBA color based on the normalized value\n",
    "    rgba_color = scalar_mappable.to_rgba(norm_value)\n",
    "\n",
    "    # Convert the RGBA color to hex\n",
    "    hex_color = mcolors.to_hex(rgba_color)\n",
    "\n",
    "    return hex_color\n",
    "\n",
    "def value_to_text_color(value, ranges): \n",
    "    norm_value = (value - ranges[0]) / (ranges[1] - ranges[0])\n",
    "    if norm_value < 0.5: \n",
    "        return \"black\"\n",
    "    else: \n",
    "        return \"white\"\n",
    "\n",
    "def make_pretty(styler):\n",
    "    styler.set_caption(\"Player Tackling Efficiency Metrics\").set_table_styles([{'selector': 'caption', 'props': 'caption-side: bottom; font-size:1.25em;'}], overwrite=False)\n",
    "    show_cols = [\"active_plays\", \"tackles_per_play\", \"tackle_opportunity_rate\", \"tackle_conversion_ratio\", \"missed_opportunity_rate\"]\n",
    "    styler.hide([col for col in styler.columns if col not in show_cols], axis=1)\n",
    "    styler.format(precision=2)\n",
    "    styler.relabel_index([\"Active Plays\", \"Tackles per Play\", \"Tackle Opportunity Rate\", \"Tackle Conversion Rate\", \"Missed Opportunity Rate\"], axis=1)\n",
    "    \n",
    "    return styler\n",
    "\n",
    "def color_rates(styler, df): \n",
    "    v_or = [df[\"tackle_opportunity_rate\"].values.min(), df[\"tackle_opportunity_rate\"].values.max()]\n",
    "    v_tackle = [df[\"tackles_per_play\"].values.min(), df[\"tackles_per_play\"].values.max()]\n",
    "    styler.map(lambda v: f'background: {value_to_cell_color(v, v_or)}; color: {value_to_text_color(v, v_or)}', subset=[\"tackle_opportunity_rate\"])\n",
    "    styler.map(lambda v: f'background: {value_to_cell_color(v, v_tackle)}; color: {value_to_text_color(v, v_tackle)}', subset=[\"tackles_per_play\"])\n",
    "\n",
    "    return styler\n",
    "\n",
    "def print_html(styled_df):\n",
    "    \n",
    "    # html with style block \n",
    "    html_with_style_block = styled_df.to_html(exclude_styles=False, doctype_html=False)\n",
    "\n",
    "    # remove style block\n",
    "    style_block_start = html_with_style_block.find('<style')\n",
    "    style_block_end = html_with_style_block.find('</style>') + len('</style>')\n",
    "    style_block = html_with_style_block[style_block_start:style_block_end]\n",
    "\n",
    "    # Remove the style block from the original HTML\n",
    "    html_without_style_block = html_with_style_block[:style_block_start] + html_with_style_block[style_block_end:]\n",
    "\n",
    "    # iterate through the style block and add the style inline to the HTML element\n",
    "    state = 0\n",
    "    styles_dict = {}\n",
    "    selectors = []\n",
    "    html_with_inline_styles = html_without_style_block\n",
    "    for line in style_block.split('\\n'):\n",
    "        if line == '<style type=\"text/css\">':\n",
    "            continue\n",
    "        if line == '</style>':\n",
    "            break\n",
    "        if state == 0:\n",
    "            if '{' in line:   # find selectors\n",
    "                state += 1\n",
    "                selectors = [l.strip().strip(\"#\") for l in line[:line.index('{')].split(\",\")]\n",
    "                styles_dict = {}\n",
    "                continue\n",
    "            else: \n",
    "                break        # end of style block\n",
    "        elif state == 1:     # find styles and store in styles_dict\n",
    "            if '}' in line:\n",
    "                for selector in selectors:\n",
    "                    style_str = \"\"\n",
    "                    for k, v in styles_dict.items():\n",
    "                        style_str += f\" {k}: {v}\"\n",
    "                    html_with_inline_styles = html_with_inline_styles.replace(selector, f'\"{selector}\" style=\"{style_str}')\n",
    "                state = 0\n",
    "            else:\n",
    "                styles = line.strip().split(':')\n",
    "                styles_dict[styles[0].strip()] = styles[1].strip()\n",
    "                continue\n",
    "\n",
    "    print(html_with_inline_styles)\n",
    "    \n",
    "df_converted_tackles[\"tackles_per_play\"] = df_converted_tackles.made_tackles/df_converted_tackles.active_plays\n",
    "df = df_converted_tackles[(df_converted_tackles.position == \"FS\") | (df_converted_tackles.position == \"SS\") | (df_converted_tackles.position == \"CB\")]\n",
    "df = df.drop(columns=[\"nflId\"])\n",
    "df = df.set_index([\"display_name\", \"position\"])     # convert name and position to indices\n",
    "df = df[[\"active_plays\", \"tackles_per_play\", \"tackle_opportunity_rate\", \"tackle_conversion_ratio\", \"missed_opportunity_rate\"]]\n",
    "# df = df.astype({\"missed_opportunities\": \"int32\"})\n",
    "df.index.rename([\"Player\", \"Position\"], level=[0, 1], inplace=True)\n",
    "df = df.sort_values(by=[\"tackles_per_play\"], ascending=False)\n",
    "# df = df.head(10)\n",
    "\n",
    "styled_df = df.style.pipe(make_pretty)\n",
    "styled_df = color_rates(styled_df, df)\n",
    "# print_html(styled_df)\n",
    "styled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output tackle opp, missed tackle opp, and rate data in HTML table format for Linebackers \n",
    "df = df_converted_tackles[(df_converted_tackles.position == \"ILB\") | (df_converted_tackles.position == \"OLB\")]\n",
    "df = df.drop(columns=[\"nflId\"])\n",
    "df = df.set_index([\"display_name\", \"position\"])     # convert name and position to indices\n",
    "df = df[[\"active_plays\", \"tackles_per_play\", \"tackle_opportunity_rate\", \"tackle_conversion_ratio\", \"missed_opportunity_rate\"]]\n",
    "# df = df.astype({\"missed_opportunities\": \"int32\"})\n",
    "df.index.rename([\"Player\", \"Position\"], level=[0, 1], inplace=True)\n",
    "df = df.sort_values(by=[\"tackles_per_play\"], ascending=False)\n",
    "\n",
    "styled_df = df.style.pipe(make_pretty)\n",
    "styled_df = color_rates(styled_df, df)\n",
    "\n",
    "styled_df\n",
    "# print_html(styled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot of missed opportunity rate vs. tackle opportunity rate for secondary and linebackers\n",
    "\n",
    "df_s = df_converted_tackles[(df_converted_tackles.position == \"FS\") | (df_converted_tackles.position == \"SS\") | (df_converted_tackles.position == \"CB\")]\n",
    "df_lb = df_converted_tackles[(df_converted_tackles.position == \"ILB\") | (df_converted_tackles.position == \"OLB\")]\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "fig.set_size_inches(15, 5)\n",
    "\n",
    "s_mean_tackle_opp = df_s.tackle_opportunity_rate.mean()\n",
    "s_mean_missed_opp = df_s.missed_opportunity_rate.mean()\n",
    "window_h = 0.12\n",
    "window_v = 0.15\n",
    "\n",
    "lb_max_tackle_opp = df_lb.tackle_opportunity_rate.max()\n",
    "lb_min_tackle_opp = df_lb.tackle_opportunity_rate.min()\n",
    "lb_max_missed_opp = df_lb.missed_opportunity_rate.max()\n",
    "lb_min_missed_opp = df_lb.missed_opportunity_rate.min()\n",
    "\n",
    "ax[0].scatter(df_s.tackle_opportunity_rate, df_s.missed_opportunity_rate, color=\"red\", s=30, alpha=0.5, label=\"Secondary\")\n",
    "ax[0].hlines(y=s_mean_missed_opp, xmin=0, xmax=1, linestyles=\"dotted\", color=\"gray\")\n",
    "ax[0].vlines(x=s_mean_tackle_opp, ymin=0, ymax=1, linestyles=\"dotted\", color=\"gray\")\n",
    "ax[0].set_xlim([s_mean_tackle_opp - window_h, s_mean_tackle_opp + window_h])\n",
    "ax[0].set_ylim([s_mean_missed_opp - window_v, s_mean_missed_opp + window_v])\n",
    "ax[0].set_xlabel(\"Tackle Opportunity Rate\", fontsize=16)\n",
    "ax[0].set_ylabel(\"Missed Opportunity Rate\", fontsize=16)\n",
    "ax[0].tick_params(axis='both', which='major', labelsize=16)\n",
    "ax[0].tick_params(axis='both', which='minor', labelsize=16)\n",
    "ax[0].set_title(\"Secondary\", fontsize=16)\n",
    "\n",
    "lb_mean_missed_opp = df_lb.missed_opportunity_rate.mean()\n",
    "lb_mean_tackle_opp = df_lb.tackle_opportunity_rate.mean()\n",
    "window_h = 0.1\n",
    "window_v = 0.19\n",
    "\n",
    "ax[1].scatter(df_lb.tackle_opportunity_rate, df_lb.missed_opportunity_rate, color=\"blue\", s=30, alpha=0.5, label=\"Linebackers\")\n",
    "ax[1].hlines(y=lb_mean_missed_opp, xmin=0, xmax=1, linestyles=\"dotted\", color=\"gray\")\n",
    "ax[1].vlines(x=lb_mean_tackle_opp, ymin=0, ymax=1, linestyles=\"dotted\", color=\"gray\")\n",
    "ax[1].set_xlim([lb_mean_tackle_opp - window_h, lb_mean_tackle_opp + window_h])\n",
    "ax[1].set_ylim([lb_mean_missed_opp - window_v, lb_mean_missed_opp + window_v])\n",
    "ax[1].set_xlabel(\"Tackle Opportunity Rate\", fontsize=16)\n",
    "ax[1].set_ylabel(\"Missed Opportunity Rate\", fontsize=16)\n",
    "ax[1].tick_params(axis='both', which='major', labelsize=16)\n",
    "ax[1].tick_params(axis='both', which='minor', labelsize=16)\n",
    "ax[1].set_title(\"Linebackers\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot tackle opportunities vs. active plays, tackle conversion rate vs. tackle opportunities, and missed opportunity rate vs. tackle opportunities for each player\n",
    "\n",
    "# Segment dataframe by position group\n",
    "df_converted_tackles_s = df_converted_tackles[(df_converted_tackles.position == \"FS\") | (df_converted_tackles.position == \"SS\") | (df_converted_tackles.position == \"CB\")]\n",
    "df_converted_tackles_lb = df_converted_tackles[(df_converted_tackles.position == \"ILB\") | (df_converted_tackles.position == \"OLB\")]\n",
    "df_converted_tackles_de = df_converted_tackles[(df_converted_tackles.position == \"T\") | (df_converted_tackles.position == \"DE\") | (df_converted_tackles.position == \"DT\")]\n",
    "\n",
    "# Tackle Opportunity Rate\n",
    "x = df_converted_tackles.active_plays.to_numpy()\n",
    "y = df_converted_tackles.tackle_opportunities.to_numpy()\n",
    "m_opt = np.dot(x, y)/np.dot(x, x)\n",
    "\n",
    "x_s = df_converted_tackles_s.active_plays.to_numpy()\n",
    "y_s = df_converted_tackles_s.tackle_opportunities.to_numpy()\n",
    "m_opt_s = np.dot(x_s, y_s)/np.dot(x_s, x_s)\n",
    "\n",
    "x_lb = df_converted_tackles_lb.active_plays.to_numpy()\n",
    "y_lb = df_converted_tackles_lb.tackle_opportunities.to_numpy()\n",
    "m_opt_lb = np.dot(x_lb, y_lb)/np.dot(x_lb, x_lb)\n",
    "print(f\"total tackle opportunity rate = {m_opt:.2f}, Safeties = {m_opt_s:.2f}, LB = {m_opt_lb:.2f}\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.linspace(200, 450, 251), m_opt * np.linspace(200, 450, 251), \"k-\")\n",
    "ax.scatter(df_converted_tackles_s.active_plays, df_converted_tackles_s.tackle_opportunities, color=\"red\", s=10, alpha=0.75, label=\"SS, FS, CB\")\n",
    "ax.scatter(df_converted_tackles_lb.active_plays, df_converted_tackles_lb.tackle_opportunities, color=\"blue\", s=10, alpha=0.75, label=\"OLB, ILB\")\n",
    "# ax.scatter(df_converted_tackles_de.active_plays, df_converted_tackles_de.tackle_opportunities, color=\"green\", s=10, alpha=0.75, label=\"DE, DT, T\")\n",
    "ax.set_xlabel(\"Active Plays\", fontsize=14)\n",
    "ax.set_ylabel(\"Tackle Opportunities\", fontsize=14)\n",
    "ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=14)\n",
    "ax.legend()\n",
    "ax.set_title(\"Tackle Opportunity Rate\")\n",
    "\n",
    "# Tackle Conversion Rate\n",
    "# Calculating best fit line for tackle conversion rate that runs through the origin\n",
    "x = df_converted_tackles.tackle_opportunities.to_numpy()\n",
    "y = df_converted_tackles.made_tackles.to_numpy()\n",
    "m_opt = np.dot(x, y)/np.dot(x, x)\n",
    "\n",
    "x_s = df_converted_tackles_s.tackle_opportunities.to_numpy()\n",
    "y_s = df_converted_tackles_s.made_tackles.to_numpy()\n",
    "m_opt_s = np.dot(x_s, y_s)/np.dot(x_s, x_s)\n",
    "\n",
    "x_lb = df_converted_tackles_lb.tackle_opportunities.to_numpy()\n",
    "y_lb = df_converted_tackles_lb.made_tackles.to_numpy()\n",
    "m_opt_lb = np.dot(x_lb, y_lb)/np.dot(x_lb, x_lb)\n",
    "print(f\"total tackle conversion rate = {m_opt:.2f}, Safeties = {m_opt_s:.2f}, LB = {m_opt_lb:.2f}\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.linspace(50, 175, 126), m_opt * np.linspace(50, 175, 126), \"k-\")\n",
    "ax.scatter(df_converted_tackles_s.tackle_opportunities, df_converted_tackles_s.made_tackles, color=\"red\", s=10, alpha=0.75, label=\"SS, FS, CB\")\n",
    "ax.scatter(df_converted_tackles_lb.tackle_opportunities, df_converted_tackles_lb.made_tackles, color=\"blue\", s=10, alpha=0.75, label=\"OLB, ILB\")\n",
    "# ax.scatter(df_converted_tackles_de.tackle_opportunities, df_converted_tackles_de.made_tackles, color=\"green\", s=10, alpha=0.75, label=\"DE, DT, T\")\n",
    "ax.set_xlabel(\"Tackle Opportunities\", fontsize=14)\n",
    "ax.set_ylabel(\"Made Tackles\", fontsize=14)\n",
    "ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=14)\n",
    "ax.legend()\n",
    "ax.set_title(\"Tackle Conversion Rate\")\n",
    "\n",
    "# Missed Opportunity Rate\n",
    "x = df_converted_tackles.tackle_opportunities.to_numpy()\n",
    "y = df_converted_tackles.missed_opportunities.to_numpy()\n",
    "m_opt = np.dot(x, y)/np.dot(x, x)\n",
    "\n",
    "x_s = df_converted_tackles_s.tackle_opportunities.to_numpy()\n",
    "y_s = df_converted_tackles_s.missed_opportunities.to_numpy()\n",
    "m_opt_s = np.dot(x_s, y_s)/np.dot(x_s, x_s)\n",
    "\n",
    "x_lb = df_converted_tackles_lb.tackle_opportunities.to_numpy()\n",
    "y_lb = df_converted_tackles_lb.missed_opportunities.to_numpy()\n",
    "m_opt_lb = np.dot(x_lb, y_lb)/np.dot(x_lb, x_lb)\n",
    "print(f\"total missed_opportunities rate = {m_opt:.2f}, Safeties = {m_opt_s:.2f}, LB = {m_opt_lb:.2f}\")\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.linspace(50, 175, 126), m_opt * np.linspace(50, 175, 126), \"k-\")\n",
    "ax.scatter(df_converted_tackles_s.tackle_opportunities, df_converted_tackles_s.missed_opportunities, color=\"red\", s=10, alpha=0.75, label=\"SS, FS, CB\")\n",
    "ax.scatter(df_converted_tackles_lb.tackle_opportunities, df_converted_tackles_lb.missed_opportunities, color=\"blue\", s=10, alpha=0.75, label=\"OLB, ILB\")\n",
    "# ax.scatter(df_converted_tackles_de.tackle_opportunities, df_converted_tackles_de.missed_opportunities, color=\"green\", s=10, alpha=0.75, label=\"DE, DT, T\")\n",
    "ax.set_xlabel(\"Tackle Opportunities\", fontsize=14)\n",
    "ax.set_ylabel(\"Missed Opportunities\", fontsize=14)\n",
    "ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=14)\n",
    "ax.legend()\n",
    "ax.set_title(\"Missed Opportunity Rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract statistics on tackle_opportunities and tackle_conversion_rate by position group \n",
    "df_converted_tackles_s = df_converted_tackles[(df_converted_tackles.position == \"FS\") | (df_converted_tackles.position == \"SS\") | (df_converted_tackles.position == \"CB\")]\n",
    "df_converted_tackles_lb = df_converted_tackles[(df_converted_tackles.position == \"ILB\") | (df_converted_tackles.position == \"OLB\")]\n",
    "\n",
    "# extract mean and std of tackle opportunities\n",
    "print(f\"Secondary Tackle Opportunity Rate: mean = {df_converted_tackles_s.tackle_opportunity_rate.mean():.3f} | std = {df_converted_tackles_s.tackle_opportunity_rate.std():.3f}\") \n",
    "print(f\"Linebacker Tackle Opportunity Rate: mean = {df_converted_tackles_lb.tackle_opportunity_rate.mean():.3f} | std = {df_converted_tackles_lb.tackle_opportunity_rate.std():.3f}\") \n",
    "\n",
    "# extract mean and std of tackle conversion rate\n",
    "print(f\"Secondary Tackle Conversion Rate: mean = {df_converted_tackles_s.tackle_conversion_ratio.mean():.3f} | std = {df_converted_tackles_s.tackle_conversion_ratio.std():.3f}\") \n",
    "print(f\"Linebacker Tackle Conversion Rate: mean = {df_converted_tackles_lb.tackle_conversion_ratio.mean():.3f} | std = {df_converted_tackles_lb.tackle_conversion_ratio.std():.3f}\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_nfl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
